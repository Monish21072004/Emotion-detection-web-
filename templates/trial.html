<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Emotion Detection System</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <!-- Orbitron font for a futuristic vibe -->
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap" rel="stylesheet">
  <style>
    /* Overall dark, futuristic background */
    body {
      background: linear-gradient(135deg, #0f2027, #203a43, #2c5364);
      color: #fff;
      font-family: 'Orbitron', sans-serif;
      min-height: 100vh;
      margin: 0;
      overflow-x: hidden;
    }
    .container {
      padding: 2rem;
    }
    /* Glassmorphism card with neon border and hover effect */
    .card {
      background: rgba(20, 30, 48, 0.75);
      border-radius: 15px;
      box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
      backdrop-filter: blur(8px);
      -webkit-backdrop-filter: blur(8px);
      border: 1px solid rgba(255, 255, 255, 0.18);
      padding: 2rem;
      transition: transform 0.3s ease, box-shadow 0.3s ease;
    }
    .card:hover {
      transform: translateY(-10px);
      box-shadow: 0 12px 48px 0 rgba(37, 117, 252, 0.6);
    }
    h1 {
      color: #e0e0e0; /* Lighter font color */
      text-align: center;
      margin-bottom: 1rem;
      font-size: 2.5rem;
      text-shadow: 0 0 10px rgba(37, 117, 252, 0.8);
    }
    /* Futuristic neon button style */
    .btn-custom {
      background: linear-gradient(45deg, #1f8ef1, #66a6ff);
      border: none;
      border-radius: 8px;
      padding: 12px 24px;
      font-size: 16px;
      color: #fff;
      text-transform: uppercase;
      letter-spacing: 1px;
      box-shadow: 0 0 10px rgba(37, 117, 252, 0.6);
      transition: transform 0.3s ease, box-shadow 0.3s ease;
      margin: 0.5rem;
      cursor: pointer;
    }
    .btn-custom:hover {
      transform: translateY(-3px);
      box-shadow: 0 0 20px rgba(37, 117, 252, 0.8);
    }
    /* Video container with neon border */
    .video-container {
      position: relative;
      width: 100%;
      max-width: 640px;
      margin: 2rem auto;
      border-radius: 15px;
      overflow: hidden;
      border: 2px solid rgba(37, 117, 252, 0.6);
      box-shadow: 0 0 20px rgba(37, 117, 252, 0.4);
    }
    #video-feed {
      width: 100%;
      transform: scaleX(-1);
      display: block;
    }
    #canvas-overlay {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none;
    }
    .result-image {
      max-width: 100%;
      border-radius: 15px;
      margin: 1rem 0;
      box-shadow: 0 0 20px rgba(37, 117, 252, 0.6);
    }
    /* Container for result image with close button */
    .result-container {
      position: relative;
      display: none;
      margin: 1rem auto;
      text-align: center;
    }
    .close-button {
      position: absolute;
      top: 5px;
      right: 10px;
      background: transparent;
      border: none;
      color: #000;  /* Black close button */
      font-size: 28px;
      cursor: pointer;
      z-index: 10;
    }
    /* Container for plots with close button */
    .plot-container {
      position: relative;
      display: none;
      margin: 1rem auto;
      text-align: center;
    }
    /* Futuristic loader spinner */
    .loading-spinner {
      border: 4px solid rgba(255, 255, 255, 0.2);
      border-top: 4px solid #1f8ef1;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      animation: spin 1s linear infinite;
      margin: 0 auto;
    }
    @keyframes spin {
      to { transform: rotate(360deg); }
    }
    /* Style the file input to blend with the theme */
    #image-input {
      background: rgba(255,255,255,0.1);
      color: #fff;
      border: none;
    }
  </style>
</head>
<body>
  <!-- Audio element for professional click sound -->
  <audio id="click-sound" src="https://upload.wikimedia.org/wikipedia/commons/2/27/Button-16.mp3" preload="auto"></audio>
  
  <div class="container">
    <div class="card">
      <h1>üé≠ Emotion Detection System</h1>
      
      <!-- Video Section -->
      <div class="text-center">
        <div class="video-container">
          <video id="video-feed" autoplay></video>
          <canvas id="canvas-overlay"></canvas>
        </div>
        <button class="btn btn-custom" onclick="startWebcam()">üé• Start Video</button>
        <button class="btn btn-custom" onclick="stopWebcam()">‚èπÔ∏è Stop Video</button>
      </div>
      
      <!-- Image Upload Section -->
      <div class="text-center mt-4">
        <input type="file" id="image-input" accept="image/*" class="form-control mb-3">
        <button class="btn btn-custom" onclick="detectEmotion()">üñºÔ∏è Detect in Image</button>
      </div>
      
      <!-- Result Container for Detected Image -->
      <div id="result-container" class="result-container">
        <button class="close-button" onclick="closeResult()">√ó</button>
        <img id="result-image" class="result-image" src="#" alt="Result">
        <h3 id="emotion-result" class="mt-3" style="color: #1f8ef1;"></h3>
      </div>
      
      <!-- Analytics Section -->
      <div class="text-center mt-4">
        <button class="btn btn-custom" onclick="plotTrainingHistory()">üìà Training History</button>
        <button class="btn btn-custom" onclick="plotConfusionMatrix()">üìä Confusion Matrix</button>
      </div>
      
      <!-- Plot Container for Training History and Confusion Matrix -->
      <div id="plot-container" class="plot-container">
        <button class="close-button" onclick="closePlot()">√ó</button>
        <img id="plot-image" class="result-image" src="#" alt="Plot">
      </div>
    </div>
  </div>

  <script>
    // Play professional click sound on any button click
    document.querySelectorAll('.btn-custom').forEach(button => {
      button.addEventListener('click', () => {
        const sound = document.getElementById('click-sound');
        sound.currentTime = 0;
        sound.play().catch(err => console.error('Audio playback failed:', err));
      });
    });

    // Function to close the result container
    function closeResult() {
      document.getElementById('result-container').style.display = 'none';
    }
    // Function to close the plot container
    function closePlot() {
      document.getElementById('plot-container').style.display = 'none';
    }

    let videoStream;
    let canvas;
    let ctx;
    let animationFrameId;
    let lastFrameTime = 0; // for throttling

    async function startWebcam() {
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        alert('Your browser does not support webcam access.');
        return;
      }
      try {
        videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
        const video = document.getElementById('video-feed');
        video.srcObject = videoStream;
        canvas = document.getElementById('canvas-overlay');
        ctx = canvas.getContext('2d');
        video.onplay = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          lastFrameTime = performance.now();
          processVideoFrame();
        };
      } catch (err) {
        alert('Error accessing webcam: ' + err);
      }
    }

    function stopWebcam() {
      if (videoStream) {
        videoStream.getTracks().forEach(track => track.stop());
        if (ctx) {
          ctx.clearRect(0, 0, canvas.width, canvas.height);
        }
        cancelAnimationFrame(animationFrameId);
      }
    }

    function processVideoFrame() {
      const currentTime = performance.now();
      // Process frame only if at least 100ms have passed
      if (currentTime - lastFrameTime >= 100) {
        lastFrameTime = currentTime;
        const video = document.getElementById('video-feed');
        if (video.srcObject && video.videoWidth > 0) {
          const tempCanvas = document.createElement('canvas');
          tempCanvas.width = video.videoWidth;
          tempCanvas.height = video.videoHeight;
          tempCanvas.getContext('2d').drawImage(video, 0, 0);
          const frameData = tempCanvas.toDataURL('image/jpeg');
          fetch('/process_frame', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ frame: frameData })
          })
          .then(response => response.json())
          .then(data => {
            if (data.faces) {
              ctx.clearRect(0, 0, canvas.width, canvas.height);
              data.faces.forEach(face => {
                ctx.strokeStyle = '#1f8ef1';
                ctx.lineWidth = 3;
                ctx.strokeRect(face.x, face.y, face.w, face.h);
                ctx.fillStyle = '#1f8ef1';
                ctx.font = '16px Orbitron, Arial';
                ctx.fillText(face.emotion, face.x, face.y - 10);
              });
            }
          })
          .catch(console.error);
        }
      }
      animationFrameId = requestAnimationFrame(processVideoFrame);
    }

    function detectEmotion() {
      const fileInput = document.getElementById('image-input');
      const file = fileInput.files[0];
      if (!file) {
        return alert('Please select an image');
      }
      document.getElementById('loader') && (document.getElementById('loader').style.display = 'block');
      const formData = new FormData();
      formData.append('file', file);
      fetch('/detect', {
        method: 'POST',
        body: formData
      })
      .then(response => response.json())
      .then(data => {
        document.getElementById('loader') && (document.getElementById('loader').style.display = 'none');
        if (data.error) return alert(data.error);
        // Display full image with detected emotion
        document.getElementById('result-image').src = `data:image/jpeg;base64,${data.image}`;
        document.getElementById('result-container').style.display = 'block';
        document.getElementById('emotion-result').textContent = `Detected Emotion: ${data.emotion}`;
      })
      .catch(err => {
        console.error(err);
        alert('Detection failed');
        document.getElementById('loader') && (document.getElementById('loader').style.display = 'none');
      });
    }

    function plotTrainingHistory() {
      fetch('/plot_training_history')
      .then(response => response.json())
      .then(data => {
        if (data.error) {
          alert(data.error);
        } else {
          document.getElementById('plot-image').src = `data:image/png;base64,${data.plot}`;
          document.getElementById('plot-container').style.display = 'block';
        }
      });
    }

    function plotConfusionMatrix() {
      fetch('/plot_confusion_matrix')
      .then(response => response.json())
      .then(data => {
        if (data.error) {
          alert(data.error);
        } else {
          document.getElementById('plot-image').src = `data:image/png;base64,${data.plot}`;
          document.getElementById('plot-container').style.display = 'block';
        }
      });
    }
  </script>
</body>
</html>
